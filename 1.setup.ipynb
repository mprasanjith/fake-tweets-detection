{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Tweets Detection using Concurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to grab the sample dataset we're using in this research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-27 02:56:27--  https://ndownloader.figshare.com/files/11767817\n",
      "Resolving ndownloader.figshare.com (ndownloader.figshare.com)... 18.203.76.79, 18.203.5.169, 34.255.246.69, ...\n",
      "Connecting to ndownloader.figshare.com (ndownloader.figshare.com)|18.203.76.79|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/11767817/PHEME_veracity.tar.bz2 [following]\n",
      "--2020-02-27 02:56:28--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/11767817/PHEME_veracity.tar.bz2\n",
      "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.97.75\n",
      "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.97.75|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 46529729 (44M) [binary/octet-stream]\n",
      "Saving to: ‘./dataset/pheme_veracity.tar.bz2’\n",
      "\n",
      "./dataset/pheme_ver 100%[===================>]  44.37M  14.1MB/s    in 3.2s    \n",
      "\n",
      "2020-02-27 02:56:31 (14.1 MB/s) - ‘./dataset/pheme_veracity.tar.bz2’ saved [46529729/46529729]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p ./dataset\n",
    "! wget \"https://ndownloader.figshare.com/files/11767817\" -O \"./dataset/pheme_veracity.tar.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar xC ./dataset -f ./dataset/pheme_veracity.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start cleaning up the dataset. Because we're not using the thread based annotation system used in this dataset, we can go ahead and flatten the folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ./flatten1\n",
    "! rsync -a ./dataset/**/**/non-rumours/* ./flatten1\n",
    "! rsync -a ./dataset/**/**/rumours/* ./flatten1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "rootdir = Path('./flatten1')\n",
    "tweet_folders = [f for f in rootdir.glob('*') if f.is_dir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PHEME Project has helpfully provided a Python method to convert the annotations into \"Verified True\", \"Verified False\" and \"Unverified\" tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_annotations(annotation, string = True):\n",
    "    if 'misinformation' in annotation.keys() and 'true'in annotation.keys():\n",
    "        if int(annotation['misinformation'])==0 and int(annotation['true'])==0:\n",
    "            if string:\n",
    "#                 label = \"unverified\"\n",
    "                label = None\n",
    "            else:\n",
    "                label = 2\n",
    "        elif int(annotation['misinformation'])==0 and int(annotation['true'])==1 :\n",
    "            if string:\n",
    "                label = \"true\"\n",
    "            else:\n",
    "                label = 1\n",
    "        elif int(annotation['misinformation'])==1 and int(annotation['true'])==0 :\n",
    "            if string:\n",
    "                label = \"false\"\n",
    "            else:\n",
    "                label = 0\n",
    "        elif int(annotation['misinformation'])==1 and int(annotation['true'])==1:\n",
    "            label = None\n",
    "            \n",
    "    elif 'misinformation' in annotation.keys() and 'true' not in annotation.keys():\n",
    "        # all instances have misinfo label but don't have true label\n",
    "        if int(annotation['misinformation'])==0:\n",
    "            if string:\n",
    "#                 label = \"unverified\"\n",
    "                label = None\n",
    "            else:\n",
    "                label = 2\n",
    "        elif int(annotation['misinformation'])==1:\n",
    "            if string:\n",
    "                label = \"false\"\n",
    "            else:\n",
    "                label = 0\n",
    "                \n",
    "    elif 'true' in annotation.keys() and 'misinformation' not in annotation.keys():\n",
    "        label = None\n",
    "    else:\n",
    "        label = None\n",
    "           \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_source_tweet_path(tweet_id):\n",
    "    return Path('./flatten1/' + tweet_id + '/source-tweets/' + tweet_id + '.json')\n",
    "\n",
    "def get_annotation_path(tweet_id):\n",
    "    return Path('./flatten1/' + tweet_id + '/annotation.json')\n",
    "\n",
    "def parse_tweet(tweet_id):\n",
    "    source_tweet_path = get_source_tweet_path(tweet_id)\n",
    "    annotation_path = get_annotation_path(tweet_id)\n",
    "    \n",
    "    with open(annotation_path) as f:\n",
    "        raw_annotation = json.load(f)\n",
    "        annotation = convert_annotations(raw_annotation)\n",
    "    \n",
    "    with open(source_tweet_path) as f:\n",
    "        raw_tweet = json.load(f)\n",
    "        parsed_tweet = {}\n",
    "#         parsed_tweet[\"id\"] = raw_tweet[\"id\"]\n",
    "        parsed_tweet[\"text\"] = raw_tweet[\"text\"]\n",
    "        parsed_tweet[\"annotation\"] = annotation\n",
    "        return parsed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [parse_tweet(tweet_folder.name) for tweet_folder in tweet_folders if tweet_folder.exists()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1705</td>\n",
       "      <td>1705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1699</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sydney cafe siege: Two gunmen and up to a doze...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text annotation\n",
       "count                                                1705       1705\n",
       "unique                                               1699          2\n",
       "top     Sydney cafe siege: Two gunmen and up to a doze...       true\n",
       "freq                                                    2       1067"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets_df = pd.DataFrame.from_dict(tweets)\n",
    "tweets_df.dropna(inplace=True)\n",
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have parsed the tweet content and the \"True\", \"False\" labels for each tweet. Let's write it to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv(\"tweets.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
